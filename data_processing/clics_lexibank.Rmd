---
title: "Preparing CLICS data from lexibank for inclusion in crosslinguistic data set"
author: "Márton Sóskuthy"
date: "15/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading data & packages

```{r}
# load packages:
library(tidyverse)
library(stringr)

clics <- read_csv('../raw_data/a4_cross_linguistic/cldf_clics_rough_smooth.csv')
  
# load supplementary data sets:
# 1) language list for clics with glottocodes
clics_ls <- read_csv('../raw_data/a4_cross_linguistic/clics_languages.csv')

# 2) language lists for autotyp with glottocodes
autotyp_ls <- read_csv('../raw_data/a4_cross_linguistic/autotyp_language_list.csv')
autotyp_add <- read_csv('../raw_data/a4_cross_linguistic/autotyp_additions_new.csv')

# 3) language info data
lang_info <- read_csv('../raw_data/a4_cross_linguistic/all_language_info.csv') %>%
	mutate_all(as.character)
clics_info <- read_csv('../raw_data/a4_cross_linguistic/clics_language_info_utf-8.csv') %>%
	mutate_all(as.character)

# 4) other data sets (for establishing overlap)
trs <- read_csv('../final_data/google_translate.csv')
chir <- read_csv('../raw_data/a4_cross_linguistic/chirila.csv')
reflex <- read_csv('../raw_data/a4_cross_linguistic/reflex_african_117.csv') %>%
	mutate_all(as.character)

# 4) PHOIBLE
phoible <- read_csv('../raw_data/a4_cross_linguistic/phoible.csv')
```

So as a first step in our pipeline, we remove all languages that we already have data for -- it is not helpful to add these in again.

```{r}
existing_ls <- unique(c(
  trs$language,
  chir$StdLanguageName,
  reflex$langue
))

# we remove variety info
existing_ls <- unique(str_match(existing_ls, "(.*?) *([(]|-[0-9]|$)")[,2])

# now we do the same for clics
clics$Language_broad <- str_match(clics$language.name, "(.*?) *([(]|,|\\[|-[0-9]|$)")[,2]

# and now we filter
clics <- filter(clics, !(Dataset!="ids" & Language_broad %in% existing_ls))
```

This hopefully avoids most overlap with the existing data. We now remove duplicate varieties from our data set: each language should be represented by a single variety. Varieties are shown in ()'s or []'s, or after a comma, so we use these to identify the variety. As a simple rule, where the language name also appears without a specific variety tag, we keep that as our data point. For other cases, we'll define defaults.

We do this only within the CLICS (non-IDS) portion of this data set for compatibility with previous analyses.

Defaults:
  - number 1 (if numbered)
  - variety with the most speakers
  - alphabetically first
  - spoken over written

```{r}
# we start by providing a list of default Ls 
# (for cases where simple heuristics don't work)

# defaults:
lang_defs <- list(
  `'Are'are`="'Are'are (1)",
  Akhvakh="Akhvakh (Northern dialect)",
  Alorese="Alorese, Baranusa",
  Arosi="Arosi (1)",
  Bai="Bai (Jianchuan)", # because this is the one exemplified in Wikipedia
  Bunak="Bunak, Bobonaro",
  Burmese="Burmese (Spoken Rangoon)",
  `Cia-Cia`="Cia-Cia, Masiri", # "Masiri ... shows the greatest amount of vocabulary in common with the standard dialect."
  Khwarshi="Khwarshi (Khwarshi dialect)", # because that's the name of the language also
  Kokoda="Kokoda, Negeri Besar", # "Kokoda proper"
  `Nga'o`="Nga'o, Oja",
  Pumi="Pumi (Taoba)", # more speakers (maybe?)
  Qiang="Qiang (Mawo)", # purely alphabetical
  Reta="Reta, Pura", # as it's mainly spoken on Pura
  `Sa'a`="Sa'a (1)",
  Sika="Sika, Tana Ai", # "used by both outsiders and insiders to refer to the people and language of the region and it is also used as a ritual language."
  Tabasaran="Tabasaran (Southern dialect)", # literary language based off of this
  Yi="Yi (Mile)",
  Bauro="Bauro (1)"
)

# we now replace the language variety names (on the right hand side of list)
# with the broad names (on the left hand side of the list); these broad names
# are the same as the broad names in Language_broad

clics$Language_temp <- clics$language.name

# (I give up: a loop!!!)

for (replacement in names(lang_defs)) {
  original <- lang_defs[[replacement]]
  clics$Language_temp[clics$Language_temp==original] <- replacement
}

# we now do the filtering:
# ... within each broad language group (i.e. group of varieties)
#     choose the variety with the same name as the name of the
#     broad group (where there wasn't such a name, we created one above
#     by giving it to the "default" variety);
#
#     there are some languages where a variety is specified, but
#     there's only one; in such cases, Language != Language_broad,
#     so this has to be accounted for
clics <- clics %>%
  group_by(Language_broad) %>%
  mutate(n=length(unique(Language_temp))) %>%
  ungroup() %>%
  filter(Dataset=="ids" | (n==1 | Language_temp==Language_broad)) %>%
  dplyr::select(-Language_temp)

# there are some cases where a single glottocode is represented by
# multiple language names / language.ids
# we have established some defaults:

#  [1] "Tsafiqui Pila"                   "Alu"                            
#  [3] "Avasö"                           "Avasö"                          
#  [5] "Ghaimuta"                        "Ghaimuta"                       
#  [7] "Malagheti"                       "Nggae"                          
#  [9] "Deing"                           "Deing"                          
# [11] "Ile Mandiri Lamaholot, Lewoingu" "Ile Mandiri Lamaholot, Lewoingu"

#to_remove <- clics %>%
#  group_by(glottocode) %>%
#  filter(length(unique(language.id)) > 1) %>%
#  ungroup() %>%
#  mutate(in_def_list=language.name %in% def_list) %>%
#  group_by(glottocode, language.id, language.name, in_def_list) %>%
#  summarise(n=n()) %>%
#  ungroup() %>%
#  arrange(glottocode, desc(in_def_list), desc(n)) %>%
#  filter(duplicated(glottocode)) %>%
#  pull(language.id)

# keep one in def list / with more entries / first one in data set
#clics <- clics %>%
#  filter(!(language.id %in% to_remove))
```

So now, hopefully, we only have a single variety per language. But we still don't have autotyp / phoible codes. So we want to generate those! The autotyp codes are tricky: we have glottolog codes for these languages, which we want to translate into autotyp ones. And then we'll get the Phoible ones... (gaah!)

Starting with autotyp codes below. If you uncomment the final two lines, this chunk produces a language list and a list of ISO639.3 codes that can be copy-pasted into a spreadsheet.

```{r}
clics_filter_list <- read_csv("../raw_data/a4_cross_linguistic/clics_filter_list-utf-8.csv") %>%
  filter(Dataset != "WOLD")

# how many Ls left?
length(unique(clics$language.id))
# 627 - dizzying...

# are their glottolog codes in autotyp??? OR their names
# in autotyp_add? we need this for adding family and
# especially area info... (possibly missing glottocodes)
# and also for matching with phoible
clics_ls <- clics %>%
  select(Dataset, language.name, glottocode) %>%
  unique()

mean(clics_ls$glottocode %in% autotyp_ls$Glottocode | clics_ls$language.name %in% autotyp_add$Language | clics_ls$language.name %in% clics_filter_list$Language)
# all languages in filter autotyp / autotyp add / clics filter list except for one

clics_ls %>% 
  filter(!(clics_ls$glottocode %in% autotyp_ls$Glottocode),
         !(clics_ls$language.name %in% autotyp_add$Language),
         !(clics_ls$language.name %in% clics_filter_list$Language))

# it is fine to remove these - all of them are dialects of
# Ls that are otherwise included - other than ahlao thavung!

clics$language.name <- recode(clics$language.name,
                              `Ahlao (Thavung)`="Ahlao Th")

clics_ls <- clics_ls %>% 
  filter((clics_ls$glottocode %in% autotyp_ls$Glottocode) |
         (clics_ls$language.name %in% autotyp_add$Language) |
         (clics_ls$language.name %in% clics_filter_list$Language))

clics <- clics %>%
  filter((clics$glottocode %in% autotyp_ls$Glottocode) |
         (clics$language.name %in% autotyp_add$Language) |
         (clics$language.name %in% clics_filter_list$Language))

# we create a list with language names and matching iso codes
iso_codes <- left_join(clics_ls, 
                       dplyr::select(autotyp_ls, Glottocode, ISO639.3),
                       by=c(glottocode="Glottocode")) %>%
  dplyr::select(language.name, ISO639.3) %>%
  unique()
#cat(iso_codes$name, sep="\n")
#cat(iso_codes$ISO639.3, sep="\n")
```

I have gone through this list and filled in NA's (mostly based on Wikipedia) where possible. The results of this are now loaded from the clics_filter_list.csv file. We use this list for several purposes. We start with some data cleaning.

(1) Exclude some explicitly marked languages: obvious duplicates & languages where no info was available
(2) Check whether any ISO codes from the other data sets are duplicated. If yes, exclude.
(3) Check whether any ISO codes in clics are duplicated. If yes, use a default list to exclude duplicates.

```{r}
clics_filter_list <- read_csv("../raw_data/a4_cross_linguistic/clics_filter_list-utf-8.csv") %>%
  filter(Dataset != "WOLD")

# clics_filter_list was originally generated directly from clics_ls
# and therefore had no clics Ls that were not in clics...
# so remove clics languages in clics_filter_list that are not
# also in clics!

clics_filter_list <- clics_filter_list %>%
  filter(!((Dataset=="CLICS") & !(Language %in% clics$language.name)) 
         )

# (1)
clics_filter_list$Action[is.na(clics_filter_list$Action)] <- ""
clics_filter_list <- clics_filter_list %>%
  filter(!((Dataset=="CLICS") & is.na(AutotypMatch)) & Action != "exclude")

# (2)
clics_filter_list <- clics_filter_list %>%
  mutate(clics = (Dataset=="CLICS") ) %>%
  group_by(AutotypMatch) %>%
  mutate(code_exists_outside_clics=sum(clics) < length(clics)) %>%
  ungroup() %>%
  filter(!(clics & code_exists_outside_clics))

# (3) print out languages with duplicates within CLICS
for (iso in unique(dplyr::filter(clics_filter_list, Dataset %in% c("CLICS", "IDS"))$AutotypMatch)) {
  temp_data <- dplyr::filter(clics_filter_list, Dataset %in% c("CLICS", "IDS") & AutotypMatch==iso)
  if (nrow(temp_data) > 1) {
    print(paste(temp_data$AutotypMatch, temp_data$Language, collapse="; "))
  }
}

def_list <- c("Colorado",
  "Abui", "Adonara Lamaholot", "Mono", "Mbambatana", "Bará", "Tsova-Tush",
  "Blablanga", "Bora", "Teiwa", "Lengo", "Ghari", "Lau North",
  "Tataba", "Lokuru", "Reefs", "Poleo", "Mandarin", "Mbilua", "Puiron",
  "Western Pantar"
  )


clics_filter_list <- clics_filter_list %>%
  group_by(AutotypMatch) %>%
  mutate(multi_in_clics = sum(clics) > 1) %>%
  filter(!clics | (!multi_in_clics | (Language %in% def_list))) %>%
  ungroup()
  
# now filtering clics_ls to reflect these changes
clics_ls <- filter(clics_ls, 
                   language.name %in% clics_filter_list$Language)

## the below should not matter (and yet it seems to...)
# clics filter list should now only have clics data
# clics_filter_list <- clics_filter_list %>%
#  filter(Dataset == "CLICS" | Dataset == "IDS")

# also filter clics to only have languages that are in filter list
clics <- filter(clics, language.name %in% clics_filter_list$Language)
```

We now add PHOIBLE info where available, and then write out to clics_language_info.csv.

```{r}
# how many?
sum((clics_filter_list$AutotypMatch %in% phoible$LanguageCode))
      
# add info to data set
clics_filter_list$PhoibleMatch <- ""
clics_filter_list$PhoibleMatch[clics_filter_list$AutotypMatch %in% phoible$LanguageCode] <- 
  clics_filter_list$AutotypMatch[clics_filter_list$AutotypMatch %in% phoible$LanguageCode]

# write out
clics_filter_list <- clics_filter_list %>%
  mutate(R_type="", Comments="") %>%
  dplyr::select(Language, Dataset, AutotypMatch, R_type, Comments, PhoibleMatch)

# don't uncomment!!
# write_csv(clics_filter_list, "../raw_data/a4_cross_linguistic/clics_language_info.csv")
```

We now merge the PHOIBLE info, trill realisation and AutoTyp info back into the original data set.

```{r}
lang_info <- lang_info %>%
  mutate(R_type=NA)
clics_info <- clics_info %>%
  mutate(Trill=NA)

all_info <- bind_rows(clics_info, lang_info)
all_info <- all_info %>%
  filter(!duplicated(Language))


clics[!(clics$language.name %in% all_info$Language),]$language.name
# all good!

clics <- left_join(clics, all_info, by=c(language.name="Language"))
```

So who's not in autotyp?

```{r}
#auto <- read_csv('../raw_data/a4_cross_linguistic/autotyp.csv')
#
#clics %>%
#  dplyr::select(Language, AutotypMatch, Dataset, family_name, macroarea, latitude, longitude) %>%
#  unique() %>%
#  filter(!(AutotypMatch %in% auto$ISO639.3)) %>%
#  write_csv('../raw_data/a4_cross_linguistic/autotyp_additions_clics.csv')
```

(In addition, we add family info, areal info, longitude and latitude.)
No, this info will be added from AutoTyp to make this data more compatible with what we already have.

```{r}
#clics_ls_to_join <- dplyr::select(clics_ls, name, family_name, macroarea, latitude, longitude) %>%
#  unique() %>%
#  filter(!(name=="Awa" & family_name=="Nuclear Trans New Guinea"), # two Ls with same name
#         !(name=="Jingpho" & is.na(longitude)),
#         !(name=="Jinuo" & is.na(longitude)),
#         !(name=="Kui" & is.na(longitude))) # these are erroneous duplicate entires
#clics <- inner_join(clics, clics_ls_to_join,
#                   by=c(Language="name")) %>%
#  dplyr::select(-Frequency, -Confidence, -References, -Language_broad, -n, -Comments)
```

We write out the resulting file.

```{r}
write_csv(clics, "../raw_data/a4_cross_linguistic/clics_lexibank_final.csv")
```
